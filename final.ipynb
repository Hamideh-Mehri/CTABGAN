{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:52:42.497125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from data_transformer import DataTransformer\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv('adult.csv')\n",
    "cat_cols = [ 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "log_cols = []\n",
    "mixed_cols= {'capital-loss':[0.0],'capital-gain':[0.0]}\n",
    "num_cols = ['age', 'fnlwgt','educational-num','hours-per-week']\n",
    "target_col = 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = DataTransformer(rawdata, cat_cols, num_cols,mixed_cols, log_cols, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "df = transformer.transformData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_info = transformer.output_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_sampler import DataSampler\n",
    "sampler = DataSampler(transformed_data, output_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the desired height/width for generating square images from the generator network that can be converted back to tabular domain \n",
    "data_dim = transformer.output_dimensions\t\t\n",
    "sides = [4, 8, 16, 24, 32]\n",
    "col_size_g = data_dim\n",
    "for i in sides:\n",
    "    if i * i >= col_size_g:\n",
    "        gside = i\n",
    "        break\n",
    "\n",
    "num_channels = 64\n",
    "#num_channels=\n",
    "# computing the dimensionality of hidden layers\n",
    "layer_dims = [(1, gside), (num_channels, gside // 2)]\n",
    "\n",
    "while layer_dims[-1][1] > 3 and len(layer_dims) < 4:\n",
    "    layer_dims.append((layer_dims[-1][0] * 2, layer_dims[-1][1] // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Batch Normalization layer with custom weight and bias initializers\n",
    "def custom_init_weights(shape, dtype=None):\n",
    "    return tf.random.normal(shape, mean=1.0, stddev=0.02, dtype=dtype)\n",
    "\n",
    "def custom_init_bias(shape, dtype=None):\n",
    "    return tf.zeros(shape, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dim = 100\n",
    "inp = tf.keras.layers.Input(shape=(1,1, random_dim + sampler.n_opt))\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=2, strides=1, padding='valid', use_bias=False)(inp)\n",
    "x = tf.keras.layers.BatchNormalization(beta_initializer=custom_init_bias,gamma_initializer=custom_init_weights)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=4, strides=2, padding='same', use_bias=True)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=4, strides=2, padding='same', use_bias=True)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "out = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=4, strides=2, padding='same', use_bias=True)(x)\n",
    "generator = tf.keras.models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1, 1, 258)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 2, 2, 256)         264192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 4, 4, 128)         524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 8, 8, 64)          131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 16, 16, 1)         1025      \n",
      "=================================================================\n",
      "Total params: 922,561\n",
      "Trainable params: 921,665\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "mainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
